{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby and Arrest Data\n",
    "\n",
    "In our merging exercises, we examined the relationship between county-level violent arrest totals and county-level drug arrest totals. In those exercises, you were given a dataset that provided you with county-level arrest totals. But that's not actually how the data is provided by the state of California. This week we will work with the *raw* California arrest data, which is not organized by county or even county-year. \n",
    "\n",
    "## Gradescope Autograding\n",
    "\n",
    "This assignment will be autograded using the same autograder we have used for our past several exercises. The only requirements for submitting this assignment are:\n",
    "\n",
    "- you may only import pandas, numpy, matplotlib, and altair.\n",
    "- you import data **from a URL** (since the autograder in the cloud won't see your file system)\n",
    "- you name your notebook file `exercise_groupby.ipynb`\n",
    "- you store your solutions in a dictionary called `results` with answers assigned to the keys provided in the prompts below.\n",
    "- your notebook runs from the start to completion without any errors. That means that for questions that (deliberately) invite you to write code that *causes* errors, before submitting comment out the code that generates the error to ensure it won't interrupt notebook execution.\n",
    "\n",
    "Your notebook will be executed by the autograder and the value of identified dictionary entries will then be checked against solution values. However, be aware TAs will _also_ review your notebooks for answers to other questions and to ensure your notebook is well written and formatted.\n",
    "\n",
    "You can check that you have answers for all questions in your `results` dictionary with this code:\n",
    "\n",
    "```python\n",
    "assert set(results.keys()) == {\n",
    "    \"ex4_num_rows\",\n",
    "    \"ex5_collapsed_vars\",\n",
    "    \"ex7_alameda_1980_share_violent_arrestees_black\",\n",
    "    \"ex11_white_drug_share\",\n",
    "    \"ex11_black_drug_share\",\n",
    "    \"ex12_proportionate\",\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "### Submission Limits\n",
    "\n",
    "Please remember that you are **only allowed four submissions to the autograder.** Your last submission (if you submit 4 or fewer times), or your third submission (if you submit more than 4 times) will determine your grade. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Import the raw California arrest data from the State Attorney General's office [here](https://openjustice.doj.ca.gov/data) by scrolling down to the \"Arrests\" category and copying the link for the \"Arrests - CSV, 6.1 MB\" file (remember: you must import your data using a link for the autograder to be able to assess your work).\n",
    "\n",
    "Note that if you were getting a `SSLError`, you can try reading a [copy of the data here.](https://github.com/nickeubank/MIDS_Data/blob/master/OnlineArrestData1980-2021.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the Group Structure of Your Data\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "What is the unit of observation for this dataset? In other words, when row zero says that there were 505 arrests for `VIOLENT` crimes, what exactly is that telling you -- 505 arrests in 1980? 505 arrests in Alameda County?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Your Assumptions\n",
    "\n",
    "It's important to be able to test whether the data you are working with really is organized the way you think it is, especially when working with groupby, so let's discuss how to check your answer to number 2 with `duplicated`. Consider the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>social_security_numbers</th>\n",
       "      <th>second_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222222222</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222222</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333333</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>333333333</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   social_security_numbers second_column\n",
       "0                111111111             a\n",
       "1                222222222             a\n",
       "2                222222222             a\n",
       "3                333333333             a\n",
       "4                333333333             b"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"social_security_numbers\": [\n",
    "            111111111,\n",
    "            222222222,\n",
    "            222222222,\n",
    "            333333333,\n",
    "            333333333,\n",
    "        ],\n",
    "        \"second_column\": [\"a\", \"a\", \"a\", \"a\", \"b\"],\n",
    "    }\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see if there are any duplicate rows in the dataset, we can use `.duplicated()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `.duplicated()` looks at each row, and returns `True` if it has seen the row it is looking at before. Note that it doesn't tag *all* the rows that look similar -- it treats the first instance of a row as unique, and only tags subsequent repitions are \"duplicates\" (You can change this behavior with keyword arguments if you want all rows tagged).\n",
    "\n",
    "Duplicated can also be used to test for duplicates on a sub-set of rows. For example, if we want to test for rows with duplicate values of the variable `social_security_numbers`, we can type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated([\"social_security_numbers\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `duplicated` is now only looking at the first column, the last row is now a duplicate (because 333333333 is duplicated), where when we considered all columns, it was not a duplicate (because the value in the second column varied. \n",
    "\n",
    "We can now pair `.duplicated()` with the `.any()` function to test for the presence of duplicates in your dataset, which is how we test if we really understand what constitutes a unique observation (i.e. if we think each row of our data is a unique person, then we shouldn't see any duplicated values of social security numbers, which are unique to each person in the United States). \n",
    "\n",
    "When you run `.any()` on an array of booleans, it returns a single value of `True` if *any* entries are `True`, and a single value of `False` if *no* entries are `True`. (You can also use `.all()` to test if all entries are false). \n",
    "\n",
    "Thus the command: `df.duplicated(['social_security_numbers'])` will return `False` if `social_security_numbers` uniquely idenfies every row in our dataset (since there are no duplicates)! If any rows are duplicated, then `social_security_numbers` doesn't uniquely identify our observations (i.e. each row does not represent a unique person):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated([\"social_security_numbers\"]).any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might feel backward, so you can also add a `not` before the test if you want. :) In fact, in my code I add an explicit test using the `assert` statement. The command `assert` says \"if the thing that follows this is `True`, don't do anything; if it's False, raise an exception. So in my code, I often write:\n",
    "\n",
    "```python\n",
    "assert not df.duplicated([\"social_security_numbers\"]).any()\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "AssertionError                            Traceback (most recent call last)\n",
    "Cell In [20], line 1\n",
    "----> 1 assert not df.duplicated([\"social_security_numbers\"]).any()\n",
    "\n",
    "AssertionError: \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(which in this case raises an exception! Because the rows *aren't* unique!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Use `duplicated` to test if the variables *you* think uniquely identify rows in your data really do uniquely identify rows. If you were wrong, update your beliefs (and your code) until you have an `assert` statement that passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Once you have a handle on how the data looks now, please **collapse the data** to be one observation per county-year-racial group. Store the number of rows in the resulting dataframe in `ex4_num_rows`.\n",
    "\n",
    "**Hint:** Think carefully about the most appropriate *aggregation function* (e.g., mean, median, sum, count) given the data we're working with!\n",
    "\n",
    "**Hint 2:** When using `groupby`, I am a HUGE fan of the `as_index=False` keyword argument (e.g., `df.groupby(\"col1\", as_index=False).mean()`). By default when you use groupby, pandas likes to make a new index out of the grouping columns. As you know, I HATE indices, and this keyword argument prevents pandas from this behavior. To illustrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>social_security_numbers</th>\n",
       "      <th>second_column</th>\n",
       "      <th>third_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>a</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222222222</td>\n",
       "      <td>a</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222222</td>\n",
       "      <td>b</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222222222</td>\n",
       "      <td>a</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>333333333</td>\n",
       "      <td>b</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   social_security_numbers second_column  third_column\n",
       "0                111111111             a           100\n",
       "1                222222222             a           200\n",
       "2                222222222             b           300\n",
       "3                222222222             a           400\n",
       "4                333333333             b           500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"social_security_numbers\": [\n",
    "            111111111,\n",
    "            222222222,\n",
    "            222222222,\n",
    "            222222222,\n",
    "            333333333,\n",
    "        ],\n",
    "        \"second_column\": [\"a\", \"a\", \"b\", \"a\", \"b\"],\n",
    "        \"third_column\": [100, 200, 300, 400, 500],\n",
    "    }\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>third_column</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social_security_numbers</th>\n",
       "      <th>second_column</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111111111</th>\n",
       "      <th>a</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">222222222</th>\n",
       "      <th>a</th>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333333333</th>\n",
       "      <th>b</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       third_column\n",
       "social_security_numbers second_column              \n",
       "111111111               a                     100.0\n",
       "222222222               a                     300.0\n",
       "                        b                     300.0\n",
       "333333333               b                     500.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without as_index=False\n",
    "df.groupby([\"social_security_numbers\", \"second_column\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>social_security_numbers</th>\n",
       "      <th>second_column</th>\n",
       "      <th>third_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111111111</td>\n",
       "      <td>a</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222222222</td>\n",
       "      <td>a</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222222</td>\n",
       "      <td>b</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333333333</td>\n",
       "      <td>b</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   social_security_numbers second_column  third_column\n",
       "0                111111111             a         100.0\n",
       "1                222222222             a         300.0\n",
       "2                222222222             b         300.0\n",
       "3                333333333             b         500.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With as_index=False\n",
    "df.groupby([\"social_security_numbers\", \"second_column\"], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mavg\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby([\u001b[39m\"\u001b[39m\u001b[39msocial_security_numbers\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msecond_column\u001b[39m\u001b[39m\"\u001b[39m], as_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m\"\u001b[39m\u001b[39mthird_column\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtransform(np\u001b[39m.\u001b[39mmean)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df[\"avg\"] = df.groupby([\"social_security_numbers\", \"second_column\"], as_index=False)[\n",
    "    \"third_column\"\n",
    "].transform(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUT** Don't use `as_index=False` when using `.transform()`â€”starting in pandas 1.5, if you use `as_index=False` and try and insert the values back into the original dataframe, you'll get an error:\n",
    "\n",
    "```python\n",
    "df[\"avg\"] = df.groupby([\"social_security_numbers\", \"second_column\"], as_index=False)[\"third_column\"].transform(np.mean)\n",
    "\n",
    "\n",
    "Only use this trick when NOT using `.transform()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "You should notice that there are significantly fewer rows in the data now. Given your answer from 3, what groups were you *collapsing* in question 4 (in other words, which different groups were being aggregated over)?\n",
    "\n",
    "Store the names of those variables **in a `list` in alphabetical order** in `results` as `\"ex5_collapsed_vars\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Racial Arrest Composition\n",
    "\n",
    "The next question we want to ask is: does the racial composition of arrests in each county vary by arrest type? In other words, do Blacks, Hispanics, Whites, and Other make up substantially different portions of the people arrested for drug offenses and violent offenses?\n",
    "\n",
    "To answer this question, we need to be able to say what proportion of all drug arrestees were Black/White/Hispanic/Other and what proportion of all violent arrestees were Black/White/Hispanic/Other *for each county and for each year*.\n",
    "\n",
    "In trying to do this, we'll need to break the problem down into pieces, starting from our goal (these quantities) and working backwards.\n",
    "\n",
    "### Exercise 6\n",
    "\n",
    "To calculate the share of all drug and violent arrestees who come from each racial group, what quantities do we need? \n",
    "\n",
    "Expressed differently, what two variables (one for drug arrests, one for violent arrests) do we need to add to our data to it allow us to calculate the share of arrestees in each county-year that come from a given racial group?\n",
    "\n",
    "Calculate these two variables (one variable for drug arrests, one for violent arrests). \n",
    "\n",
    "**Hint:** `transform` should probably make an appearance here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** This types of groupby manipulations are an easy place to do things wrong, so it's important to eye-ball your data to be sure you did things right! \n",
    "\n",
    "Take a look at the data for, say, Alameda County in 1980, and compare the values that you calculate above with what you get if you try to calculate those same numbers by hand using the raw data from Exercise 5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "Now calculate the share of violent and drug arrestees in each county and year from each racial group.\n",
    "\n",
    "To ensure you're on the right track, store the share (between zero and one) of violent arrestees in Alameda County in 1980 who were Black as `ex7_alameda_1980_share_violent_arrestees_black`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "We're about to start studying this data by plotting the share of violent arrestees that are Black against the share of felony drug arrestees that are Black. But the moment where you finish your data manipulations and are about to start you data analysis is a *great* time to just make sure everything in your data looks good. Let's run a few checks:\n",
    "\n",
    "- Are your values of the share of felony arrestees who were arrested for violent crimes sensible?\n",
    "- You're about to analyze the data using only the rows for the Black racial group. How many unique counties are there with data for Black arrestees? How many for White arrestees? Do you remember how many counties there are in CA (google is your friend if not!)?\n",
    "\n",
    "Include assert statements to check all these features of your data.\n",
    "\n",
    "(Reminder: the autograder will only work if you are entire notebook runs without errors.)\n",
    "\n",
    "If you encounter any problems, make sure you understand why they are happening, and fix them (if a fix is appropriate!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "Now check to see if you have the same number of counties *in each year for each racial group*.\n",
    "\n",
    "Can you figure out why there aren't? (Hint: this isn't trivial to figure out! You'll probably have to do some detective work, and even then you'll have to make a bit of a \"best guess\" at what's going on!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "Once you think you have a theory of the case, fix the problem. Again, this will NOT be trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "\n",
    "Now that you have corrected your problem, averaging over the values for each county-year, calculate the average share of drug arrestees who are Black and the average share of drug arrestees who are White. Store the results as `\"ex11_white_drug_share\"` and `\"ex11_black_drug_share\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12\n",
    "\n",
    "Plot the share of violent arrestees that are Black against the share of felony drug arrestees that are Black. Do they look proportionate? Answer in text here.\n",
    "\n",
    "Do Black arrestees make up a greater share of violent arrestees, or a greater share of drug arrestees? Store you answer as `\"greater violent\"`, or `\"greater drug\"` in `\"ex12_proportionate\"`.\n",
    "\n",
    "**Hint:** You can add a 45 degree reference line by making a dummy dataset with one point at 0,0 and one point at a location near the top of your data (e.g. 0.7, 0.7). Without a reference line it's VERY hard to be sure if how your points relate to proportionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A quick note of warning on interpretation: these results can tell you whether Black Californians make up a larger proportion of *arrests* for certain types of crimes, not whether they make up a larger proportion of people who *commit* a give type of crime! Those *might* be the same, but they might not... this data just can't answer that question.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "718fed28bf9f8c7851519acf2fb923cd655120b36de3b67253eeb0428bd33d2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
